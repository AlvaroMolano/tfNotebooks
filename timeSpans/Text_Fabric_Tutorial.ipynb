{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; font-size: 120%\">\n",
    "<h1>Text-Fabric Tutorial</h1>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"images/tf.png\" \n",
    "style=\"width:250px; height:150px;\"\n",
    ">\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"images/vuEtcbc.png\"\n",
    "style=\"width:315px; height:150;\"\n",
    ">\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "<p style='clear:both'>In this project, we use the [Text-Fabric](https://github.com/ETCBC/text-fabric) Python package combined with the Biblical Hebrew data from the [Eep Talstra Centre for Bible and Computer](http://www.wi.th.vu.nl). This notebook provides the basic set-up and introduction to the api for using Text-Fabric.</p>\n",
    "\n",
    "<p> The api information contained below is important for understanding the Time_Spans.ipynb</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Set-Up\n",
    "\n",
    "First you need to [install the text-fabric package](https://github.com/ETCBC/text-fabric/wiki#install). Uncomment and run the bash script below to install it. If you need `sudo`, you have to run the command directly in terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#pip install text-fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to download the data. Specify the directory where you would like the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = '/Users/Cody/Desktop' # specify your directory here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initiate the download. Uncomment and run the bash script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%bash -s \"$data_dir\"\n",
    "#cd $1\n",
    "#git clone https://github.com/ETCBC/text-fabric-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to access and process the Hebrew data in Text-Fabric!\n",
    "\n",
    "First we need to get the processing object, `Fabric`, from the tf.fabric module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the Fabric object, and pass it the `locations` and `modules` keyword argument. `locations` tells the processor where the data is. `modules` tells it which language and database module to load. The values are strings containing the directory paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.3.0\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "108 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "tf_data = os.path.join(data_dir, 'text-fabric-data') # get the tf data dir\n",
    "\n",
    "text_fabric = Fabric(locations=tf_data,         # instantiate processor\n",
    "                     modules='Hebrew/etcbc4c')  # path within TF data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You should see ^ \"108 features found and 0 ignored\"* and no <span style='color: red;'>red</span> error messages.*\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Text-Fabric Data Format\n",
    "\n",
    "Text-Fabric uses [its own data format](https://github.com/ETCBC/text-fabric/wiki/Data-model), which are a set of plain-text files containing rows of data (loaded as strings) for each linguistic object in the database. Each consecutive row of data corresponds with a node number, which itself corresponds with a linguistic object (i.e. a clause, phrase, word):\n",
    "\n",
    "*ex:*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;*prep*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;*subs*\n",
    "\n",
    "In the TF data file, \"prep\" corresponds to node 1 since it is the first row; it also corresponds to the first word in the database. \"subs\" corresponds to node 2, etc.\n",
    "\n",
    "Word-level nodes also function as the \"slot\" or the most atomic linguistic object in the ETCBC database. Words are numbered consecutively up until the last word in the database. After the last word, the node count resumes for linguistic objects that contain the words:\n",
    "\n",
    "*ex:*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;*426582&nbsp;&nbsp; 1-11*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;*12-18*\n",
    "\n",
    "Here we have the first two clauses in a TF data file. The row specifies that the node count starts at 426582 (the first node number after the last word in the database) and contains slots (nodes/words) 1-11; this is the first clause in the database. The node count resumes in the next row with node 426583 and contains slots/words 12-18. Text-Fabric only needs the first node number to set the count as it accesses the files and reads the data rows.\n",
    "\n",
    "The Text-Fabric format was built specifically for simple and efficient text processing with Python. It is the successor to [LAF-Fabric](https://github.com/ETCBC/laf-fabric), which used the ISO-standard XML LAF format. Use of LAF-Fabric during research led to the desire for a more \"stripped down\" format that removed the beaurocracy and efficiently loaded data for processing with Python or R.\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Loading TF Data\n",
    "\n",
    "We have already told TF where the data files are located. Now we need to tell it which data to load into memory. Data on linguistic objects are called \"features\" in TF. Features are loaded by calling the `load` method on the text-fabric object. We assign it to a variable so we can acccess those features.\n",
    "\n",
    "The features are loaded as the argument, which is a string; the features are separated by spaces. When the features are loaded for the first time, the program takes a bit longer as it compiles and compresses the data. \n",
    "\n",
    "All available features for the ETCBC Hebrew Bible are listed in the [TF feature documentation](https://etcbc.github.io/text-fabric-data/features/hebrew/etcbc4c/0_overview.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.00s B chapter              from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.01s B verse                from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.20s B g_word_utf8          from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.17s B lex_utf8             from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.07s B function             from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.22s B pdp                  from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.13s B vt                   from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.13s B lex                  from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.21s B mother               from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.03s B tab                  from /Users/Cody/Desktop/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.00s Feature overview: 102 nodes; 5 edges; 1 configs; 7 computeds\n",
      "  6.06s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "tf = text_fabric.load('''\n",
    "                      book chapter verse \n",
    "                      function pdp vt\n",
    "                      lex lex_utf8 g_word_utf8\n",
    "                      mother tab\n",
    "                      ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also call a method `makeAvailableIn` that globalizes the object variables. The object variable names are limited to single letters, so there is little danger of writing over them. However without doing this, accessing data would require something like: `tf.F.otype.s('word')`, which can become cumbersome. With this call we can write something like\n",
    "`F.otype.s('word')` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## TF API, Basics\n",
    "\n",
    "For the full api, see the [Text-Fabric Documentation](https://github.com/ETCBC/text-fabric/wiki)\n",
    "\n",
    "We iterate through TF data with generator objects, call features with feature objects, and move up / down between container and contained with a layer object:\n",
    "\n",
    "### `F.otype.s('object')`  \n",
    "**a generator that iterates through all specified objects in the database:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426581 words in the ETCBC Hebrew database...\n"
     ]
    }
   ],
   "source": [
    "word_generator = F.otype.s('word')\n",
    "\n",
    "all_words = list(word_generator) # expand to list\n",
    "word_count = len(all_words)\n",
    "\n",
    "print('{} words in the ETCBC Hebrew database...'.format(word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator returns the node numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five word nodes in database: \n",
      "[1, 2, 3, 4, 5]\n",
      "\n",
      "Last five word nodes in database: \n",
      "[426577, 426578, 426579, 426580, 426581]\n"
     ]
    }
   ],
   "source": [
    "print('First five word nodes in database: ')\n",
    "print(all_words[:5])\n",
    "print()\n",
    "print('Last five word nodes in database: ')\n",
    "print(all_words[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `F.feature.v(node)`\n",
    "**call the features for a given node:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'רֵאשִׁ֖ית'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_word = all_words[1]\n",
    "\n",
    "F.g_word_utf8.v(second_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linguistic data is also available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subs'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pdp.v(second_word)   # phrase-dependent part of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `L.u(node, otype='object')`\n",
    "**find an embedding linguistic object:**\n",
    "\n",
    "In this case, we return the clause node that `second_word` is contained within..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426582,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clause_node_tuple = L.u(second_word, otype='clause')\n",
    "\n",
    "clause_node_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object outputs a tuple to handle possibilities of multiple assignment. However, in the ETCBC dataset, words are never assigned more than once. So this object is often indexed to pull the node number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clause_node = clause_node_tuple[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `L.d(node, otype='object')`\n",
    "Now we go in the reverse direction, a \"layer down.\" Using the clause node, we look up every phrase node contained within it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(605144, 605145, 605146, 605147)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_nodes = L.d(clause_node, otype='phrase')\n",
    "\n",
    "phrase_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call features on phrases: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time\n",
      "Pred\n",
      "Subj\n",
      "Objc\n"
     ]
    }
   ],
   "source": [
    "for phrase in phrase_nodes:\n",
    "    print(F.function.v(phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, we can use the `L.d` object to move back down to the word levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clause_words = L.d(clause_node, otype='word')\n",
    "\n",
    "clause_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `T.text(word_nodes)`\n",
    "**return a plain text representation for multi-word linguistic objects**\n",
    "\n",
    "Now we take clause words, a list of word nodes, and feed it to the `T.text` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(clause_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"In the beginning, God created the sky and the land...\"\n",
    "\n",
    "The output formats the `UTF-8` plain text for the entire clause (since some words in Hebrew are prefixed directly to other words).\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "These are all of the TF objects and methods utilized in [Time_Spans.ipynb]() for the time spans project. However, there are many more methods available in the [Text-Fabric Documentation](https://github.com/ETCBC/text-fabric/wiki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
