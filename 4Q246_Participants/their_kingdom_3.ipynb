{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 of the Investigation into \"their kingdom\" of 4Q246 II.2\n",
    "\n",
    "<img src=\"images/their_kingdom.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook last updated on 2017-05-24 16:03:23.982911\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(f'Notebook last updated on {datetime.now().__str__()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the two previous notebooks, `their_kingdom_1.ipynb` and `their_kingdom_2.ipynb`, we explored two issues related to the identification of the antecedent for the 3MP suffix on מלכותהן (\"their kingdom\"), a kingdom that the text develops as temporary and destructive. Does the 3MP refer to those who name the \"son of God,\" thereby tying him in with the bad kingdom? In `their_kingdom_1.ipynb` we found that the conditions are present in 4Q246 for a disconnect between the 3MP of \"they will name him\" and \"their kingdom,\" due to the parallel construction with a passive verb and the use of an impersonal subject. This raised the possibility of a different antecedent. One attractive option in col. 1 is an apparent reference to a \"king(s) of Assyria and Egypt,\" but the question remained whether that expression could indeed be plural. The second notebook, `their_kingdom_2.ipynb`, looked for plural verbs with singular subjects in construct with coordinated nomen recta. It found parallels in Gen 14:10 and Isaiah 63:15, but the construction is clearly rare. \n",
    "\n",
    "## Research Question\n",
    "**But what are the conditions that give rise to a suffix-antecedent connection that spans several clauses?** Is such a scenario rare?\n",
    "\n",
    "That is the question which motivates the present notebook. The answer has the potential to not only influence the investigation into the 3MP of \"their kingdom,\" but also the interpretation of the 3MS on \"his/its/their kingdom\" (מלכותה, col.2 ln. 5), which remains controversial as well, and for which pro-messianic readings propose another suffix-antecedent connection that spans multiple clauses.\n",
    "\n",
    "## Goal\n",
    "Get instances from the HB wherein: \n",
    "1. a clause atom's mother is several clauses away\n",
    "2. a third person suffix is attached to a subject\n",
    "3. the clause atom's mother contains a noun which agrees with the clause's suffixed subject.\n",
    "\n",
    "Then export the instances to a spreadsheet to be manually labeled whether the suffix antecedent and the substantive antecedent is the same. \n",
    "\n",
    "Finally, analyze the circumstances which surround the connections. **What kinds of features are present in such a distance construction? What kinds of elements help disambiguate or clarify the distant connection?**\n",
    "\n",
    "## Functions\n",
    "\n",
    "The functions from the `participant_functions` directory, specifically `pgn.py` and `subjects.py`, will be important for this notebook.\n",
    "\n",
    "Also the following is important:\n",
    "* `dist` - [distance to mother](https://etcbc.github.io/text-fabric-data/features/hebrew/etcbc4c/dist), to determine that a mother clause is N away. The feature documentation urges caution for this feature, since it is inconsistently applied, and advises that the distance be calculated directly by taking the difference between the mother and daughter. We will do this in the code.\n",
    "\n",
    "* the referent \"king(s) of Assyria and Egypt\" occurs about 9 clauses away from the suffix. The 3MS referent for \"his/its kingdom\" occurs 3 clause atoms away. We will start with clause atoms with a distance from their mothers of 3. If those results are too numerous, we will gradually extend out moving up to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.01s B chapter              from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.01s B verse                from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.12s B prs                  from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.12s B prs_nu               from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.12s B prs_ps               from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.12s B prs_gn               from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.12s B ps                   from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.10s B gn                   from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.12s B nu                   from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.18s B mother               from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.07s B function             from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.12s B pdp                  from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.21s B typ                  from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.20s B rela                 from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.02s B tab                  from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.02s B domain               from /Users/Cody/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s Feature overview: 103 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "  6.29s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "# begin code\n",
    "\n",
    "# import tools\n",
    "import collections, csv\n",
    "\n",
    "# import text fabric\n",
    "from tf.fabric import Fabric\n",
    "\n",
    "# instantiate TF processor\n",
    "TF = Fabric(modules='hebrew/etcbc4c', silent=True)\n",
    "\n",
    "# load TF features\n",
    "api = TF.load('''\n",
    "              book chapter verse\n",
    "              prs prs_nu prs_ps prs_gn\n",
    "              ps gn nu\n",
    "              mother function pdp \n",
    "              typ rela tab domain\n",
    "              ''')\n",
    "\n",
    "# prevent having to prefix all functions with .api\n",
    "# also necessary for the pgn.py and subject.py functions\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import special, custom functions for subject and person, gender, number matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import participant_functions.pgn as pgn\n",
    "import participant_functions.subjects as subj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Now we compose the query and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_distant_referent(ca, min_dist=3):\n",
    "    \n",
    "    '''\n",
    "    Return dict data on a clause atom if it is a match for:\n",
    "        * its mother is several clause atoms away\n",
    "        * a third person suffix is attached to its subject\n",
    "        * its mother contains a noun which agrees \n",
    "            with the clause atom's suffixed subject.\n",
    "    \n",
    "    Require a clause atom node number.\n",
    "    Optional parameter for min_dist for the minimum distance of\n",
    "        a clause atom from its mother.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # /1/ Check parameters for target clause atom //\n",
    "    \n",
    "    # get mother\n",
    "    mother = E.mother.f(ca)[0] if E.mother.f(ca) else None\n",
    "    \n",
    "    # no match if no mother\n",
    "    if not mother:\n",
    "        return None\n",
    "    \n",
    "    # check distance to mother against min_distance\n",
    "    distance = ca - mother\n",
    "    # no match if not min\n",
    "    if distance < min_dist:\n",
    "        return None\n",
    "    \n",
    "    # check/get subject(s) word (to check for suffixes)\n",
    "    subject = tuple(word for phrase in L.d(ca, otype='phrase')\n",
    "                       for word in L.d(phrase, otype='word')\n",
    "                    \n",
    "                       # word must be in subj phrase\n",
    "                       if F.function.v(phrase) == 'Subj'\n",
    "                    \n",
    "                       # word must be the subject noun\n",
    "                       and subj.validate_subject(word)\n",
    "                    )\n",
    "    \n",
    "    # don't match plural or ø subjects\n",
    "    if len(subject) > 1 or not subject:\n",
    "        return None\n",
    "    \n",
    "    # isolate subject from tuple\n",
    "    subject = subject[0]\n",
    "    \n",
    "    # don't match ø pronominal suffix or non-third person pr.sffx.\n",
    "    if F.prs.v(subject) in {'n/a','absent'} or F.prs_ps.v(subject) != 'p3':\n",
    "        return None\n",
    "    \n",
    "    # get PGN data for pronominal suffix\n",
    "    prs_pgn = pgn.get_pgn(subject, pronom=True)\n",
    "    \n",
    "    \n",
    "    # /2/ Check parameters for mother clause atom //\n",
    "    \n",
    "    # get the subject from the mother clause\n",
    "    mother_subj = tuple(word for phrase in L.d(mother, otype='phrase')\n",
    "                           for word in L.d(phrase, otype='word')\n",
    "                           if F.function.v(phrase) == 'Subj' # word in subj phrase\n",
    "                           and subj.validate_subject(word) # word is subject noun\n",
    "                        )\n",
    "    \n",
    "    # don't match plural or ø mother subjects\n",
    "    if len(mother_subj) > 1 or not mother_subj:\n",
    "        return None\n",
    "    \n",
    "    # isolate mother subject from the tuple\n",
    "    mother_subj = mother_subj[0]\n",
    "    \n",
    "    # get the PGN for the mother's subject\n",
    "    mother_pgn = pgn.get_pgn(mother_subj)\n",
    "    \n",
    "    \n",
    "    # /3/ compare the target clause atom parameters with its mother's //\n",
    "    \n",
    "    # match if pgn of suffix and mother subject agree\n",
    "    if pgn.match_pgn(prs_pgn, mother_pgn):\n",
    "        \n",
    "        # ASSEMBLE MATCH DATA\n",
    "        \n",
    "        # format reference\n",
    "        book, chapter, verse1, = T.sectionFromNode(ca)\n",
    "        verse2 = T.sectionFromNode(mother)[2]\n",
    "        reference = f'{book} {chapter}:{verse1}' if verse1 == verse2\\\n",
    "                        else f'{book} {chapter}:{verse1}-{verse2}'\n",
    "\n",
    "        # assemble match text\n",
    "        ca_words = L.d(ca, otype='word') # get target clause atom words\n",
    "        mother_words = L.d(mother, otype='word') # get mother ca words\n",
    "        ca_text, mo_text = T.text(ca_words), T.text(mother_words) # convert words to text\n",
    "        match_text = f'{mo_text}\\n...\\n{ca_text}' # assemble into string\n",
    "\n",
    "        # get suffix/subj text\n",
    "        sfx_text = T.text([subject])\n",
    "        sbj_text = T.text([mother_subj])\n",
    "\n",
    "\n",
    "        # get all the text from mother to daughter to aid manual sorting\n",
    "\n",
    "        # get get all intervening clause atoms\n",
    "        all_cas = range(mother-5, ca+6) # -2 and +3 to catch a bit before and after\n",
    "\n",
    "        # assemble clause atom text to this list\n",
    "        # include indentation data for analyzing the clause hierarchy\n",
    "        # TODO: clean up this code with more separation and notation\n",
    "        cas_text = []\n",
    "        cas_types = []\n",
    "        cas_domains = []\n",
    "        for cla in all_cas:\n",
    "            marker = '*' if cla in {mother, ca} else ''\n",
    "            indent = '–' * F.tab.v(cla)\n",
    "            ca_words = L.d(cla, otype='word') # words for plain text\n",
    "            ca_text = T.text(ca_words) # get plain text\n",
    "            cas_text.append(f'{ca_text}{marker}{indent}')\n",
    "            cas_types.append(F.typ.v(cla))\n",
    "            cas_domains.append(F.domain.v(L.u(cla, otype='clause')[0]))\n",
    "        context_text = '\\n'.join(cas_text)    \n",
    "        context_types = '\\n'.join(cas_types)\n",
    "        context_domains = '\\n'.join(cas_domains)\n",
    "\n",
    "        # return match data\n",
    "        return {'reference':reference,\n",
    "                'match_text':match_text,\n",
    "                'distance':distance,\n",
    "                'same?':'', # field for manual notations\n",
    "                'notes':'', # field for manual notations\n",
    "                'suffix':sfx_text,\n",
    "                'subject':sbj_text,\n",
    "                'sfx_pgn':prs_pgn,\n",
    "                'sbj_pgn':mother_pgn,\n",
    "                'context':context_text,\n",
    "                'con_typs':context_types,\n",
    "                'con_doms':context_domains,\n",
    "                'ca_typ':F.typ.v(ca),\n",
    "                'mo_typ':F.typ.v(mother),\n",
    "                'ca':ca,\n",
    "                'mother':mother\n",
    "               }\n",
    "        \n",
    "    # not a match\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Query in the HB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 113 results!\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# find matches from all clause atoms in HB\n",
    "for clause_atom in F.otype.s('clause_atom'):\n",
    "    \n",
    "    # run the match function\n",
    "    is_match = match_distant_referent(clause_atom)\n",
    "    \n",
    "    # append matches to results\n",
    "    if is_match:\n",
    "        results.append(is_match)\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print(f'Done with {len(results)} results!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we export the results to a csv file for manual processing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ('reference','match_text',\n",
    "          'distance','same?',\n",
    "          'notes','suffix',\n",
    "          'subject','sfx_pgn',\n",
    "          'sbj_pgn','context','con_typs',\n",
    "          'con_doms','ca_typ','mo_typ',\n",
    "          'ca','mother')\n",
    "\n",
    "export_file = 'results/distant_suffixes_HB.csv'\n",
    "\n",
    "# export commented out to protect written files\n",
    "with open(export_file, 'w') as outfile:\n",
    "    \n",
    "    writer = csv.DictWriter(outfile, fieldnames=fields)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**View the results.**](results/distant_suffixes_HB.csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
