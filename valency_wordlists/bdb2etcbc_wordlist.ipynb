{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Wordlists from BDB to ETCBC\n",
    "\n",
    "The goal of this notebook is to map lexemes already categorised into categories useful for valency research from BDB to the ETCBC database. Each lexeme will be converted to the ETCBC transliterated [`lex` feature](https://etcbc.github.io/text-fabric-data/features/hebrew/etcbc4c/lex.html) to facilitate its use with Text-Fabric.\n",
    "\n",
    "This notebook uses the part of speech list generated in [BDB_pos_categorization.ipynb](https://github.com/codykingham/textfabric_notebooks/blob/master/valency_wordlists/BDB_pos_categorization.ipynb)\n",
    "\n",
    "The source for the BDB resource is openscriptures' [BrownDriverBriggs.xml](https://github.com/openscriptures/HebrewLexicon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.0.0\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data/features/hebrew/etcbc4c/0_overview.html\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "106 features found and 0 ignored\n",
      "\n",
      "  0.00s loading features ...\n",
      "   |     0.04s B otype                from /Users/Cody/github/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.23s B g_cons_utf8          from /Users/Cody/github/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.25s B g_lex_utf8           from /Users/Cody/github/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.26s B g_word_utf8          from /Users/Cody/github/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.18s B lex                  from /Users/Cody/github/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.01s B voc_utf8             from /Users/Cody/github/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.01s B gloss                from /Users/Cody/github/text-fabric-data/Hebrew/etcbc4c\n",
      "   |     0.00s Feature overview: 101 nodes; 4 edges; 1 configs; 6 computeds\n",
      "  6.15s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "from tf.fabric import Fabric\n",
    "TF = Fabric(modules='Hebrew/etcbc4c')\n",
    "print()\n",
    "api = TF.load('otype lex g_lex_utf8 voc_utf8 g_word_utf8 g_cons_utf8 gloss')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'of kind': 'person', 'pos': 'n.pr.gent', 'type': 'agent'},\n",
       " {'of kind': 'abstract', 'pos': 'n.pl.m', 'type': 'object'},\n",
       " {'of kind': 'name', 'pos': 'n.pr.font', 'type': 'place'},\n",
       " {'of kind': 'person', 'pos': 'n.pr.pl.gent.', 'type': 'agent'},\n",
       " {'of kind': 'person', 'pos': 'n.pr.pers.m', 'type': 'agent'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import csv\n",
    "\n",
    "tree = etree.parse(\"BrownDriverBriggs.xml\")\n",
    "root = tree.getroot()\n",
    "namespace = {'None':'http://openscriptures.github.com/morphhb/namespace'}\n",
    "\n",
    "with open('BDB_pos_tags.csv','r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    pos_tags = list(dic for dic in reader)\n",
    "    \n",
    "pos_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather all of the lemmas to test against ETCBC\n",
    "\n",
    "test_group = list()\n",
    "\n",
    "for tag in pos_tags:\n",
    "    pos = tag['pos']\n",
    "    for entry in root.findall('None:part/None:section/None:entry/None:pos', namespace):\n",
    "        cur_pos = entry.text\n",
    "        if cur_pos == pos:\n",
    "            parent = entry.getparent()\n",
    "            text = parent.findall('None:w', namespace)[0]\n",
    "            test_group.append(text.text)\n",
    "len(test_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections as col\n",
    "\n",
    "def collect_letters():\n",
    "    consonants = set()\n",
    "    vowels = set()\n",
    "    sample_words = F.otype.s('word')\n",
    "    for word in sample_words:\n",
    "        for letter in F.g_cons_utf8.v(word):\n",
    "            if letter not in {' ','ׁ','ׂ'}:\n",
    "                consonants.add(letter)\n",
    "    for word in sample_words:\n",
    "        for letter in F.g_lex_utf8.v(word):\n",
    "            if letter not in consonants and letter not in {' '}:\n",
    "                vowels.add(letter)\n",
    "    return {'consonants' : consonants, 'vowels' : vowels}\n",
    "            \n",
    "def strip_diacritic(word, consonants, vowels):\n",
    "    new_word = ''\n",
    "    for letter in word:\n",
    "        if letter in consonants or letter in vowels:\n",
    "            new_word += letter\n",
    "            \n",
    "    return new_word\n",
    "\n",
    "def fix_holem(word):\n",
    "    '''\n",
    "    fixes a vocalisation error on etcbc4c words:\n",
    "    ex: 'גֹּויִם into גּוֹיִם'\n",
    "    '''\n",
    "    if 'ֹו' in word:\n",
    "        return word.replace('ֹ', '').replace('ו','וֹ')\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "def fix_word(word):\n",
    "    clean_word = strip_diacritic(word, letters['consonants'], letters['vowels'])\n",
    "    clean_word = fix_holem(clean_word)\n",
    "    try:\n",
    "        if word[1] == 'ּ': #dagesh\n",
    "            clean_word = clean_word.replace('ּ','',1)\n",
    "    except:\n",
    "        pass\n",
    "    return clean_word\n",
    "    \n",
    "def text_to_lex():\n",
    "    text_dict = col.defaultdict(set)\n",
    "    for word in F.otype.s('word'):\n",
    "        no_diacritics = fix_word(F.g_word_utf8.v(word))\n",
    "        lex = F.lex.v(word)\n",
    "        text_dict[F.g_lex_utf8.v(word)].add(lex)\n",
    "        text_dict[no_diacritics].add(lex)\n",
    "    return text_dict\n",
    "    \n",
    "def match_etcbc(bdb_lex, bib_lex):     \n",
    "    clean_bdb_lex = fix_word(bdb_lex)\n",
    "    if clean_bdb_lex in bib_lex:\n",
    "        return bib_lex[clean_bdb_lex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bib_lex = text_to_lex()\n",
    "letters = collect_letters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_group = set()\n",
    "\n",
    "for lex in test_group:\n",
    "    if match_etcbc(lex, bib_lex):\n",
    "        match_group.add(lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not yet mapped to ETCBC:  249\n"
     ]
    }
   ],
   "source": [
    "print('Not yet mapped to ETCBC: ', len(set(test_group) - match_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(ו)יעשׂו',\n",
       " '(וְ)יַעֲזִיאֵל',\n",
       " ']עֵת] קָצִין',\n",
       " 'אֱלִיפָל',\n",
       " 'אֲזַנְיָ֫הוּ',\n",
       " 'אֲחַשְׁוֵרוֹשׁ',\n",
       " 'אֲלִיפֶ֫לֶט',\n",
       " 'אֲלִישָׁה',\n",
       " 'אֲנָֽחֲרָ֑ת',\n",
       " 'אֲפָֽרְסַתְּכָיֵא',\n",
       " 'אֲרְיוֹךְ',\n",
       " 'אֲרִידַי',\n",
       " 'אֲרַק',\n",
       " 'אֲרָא',\n",
       " 'אֲרָב',\n",
       " 'אֲרוּמָה',\n",
       " 'אֳלִיאָ֫תָה',\n",
       " 'אִישׁ הוֹד',\n",
       " 'אִישׁ־בֹ֫שֶׁת',\n",
       " 'אֵסַרְחַדֹּן',\n",
       " 'אֶ֫בֶץ',\n",
       " 'אֶדְרַע',\n",
       " 'אֶשְׁתְּמוֹעַ',\n",
       " 'אַחְבָן',\n",
       " 'אַחֲרַח',\n",
       " 'אַלַּמֶּלֶךְ',\n",
       " 'אַרְוָד',\n",
       " 'אַרְכְּוָיֵ',\n",
       " 'אַשְׁכְּנַז',\n",
       " 'אָזֵן',\n",
       " 'אׇֽסְנַפַּר',\n",
       " 'בַ֫עַל גַּד',\n",
       " 'בְּאֵר לַחַי רֹאִי',\n",
       " 'בְּאֵר שֶׁ֫בַע',\n",
       " 'בֵּֽיתְאֵל',\n",
       " 'בֵּית אַֽרְבֵֿאל',\n",
       " 'בֵּית הַיְשִׁימוֹת',\n",
       " 'בֵּית הַמֶּרְחָק',\n",
       " 'בֵּית חוֹרֹן',\n",
       " 'בֵּית לְעַפְרָה',\n",
       " 'בֵּית מַעֲכָה',\n",
       " 'בֵּית רָפָא',\n",
       " 'בֶּן־אֲבִינָדָב',\n",
       " 'בֶּן־גֶּ֫בֶר',\n",
       " 'בֶּן־דֶּ֫קֶר',\n",
       " 'בֶּן־חֶ֫סֶד',\n",
       " 'בֶּן־חוּר',\n",
       " 'בַּעַלְיָה',\n",
       " 'בַּקָּרָה',\n",
       " 'בָּרַכְאֵל']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(test_group) - match_group)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems in the mapping so far:\n",
    "* Most of the issues seem to be arising from proper nouns?\n",
    "* differences in vocalization, arising from??\n",
    "\n",
    "Fixed problems:\n",
    "* √ removed diacritical markers from both etcbc and bdb lemmas (`clean_word()`)\n",
    "    * brought the un-mapped down from ~700 to ~350\n",
    "* √ removed first position dageshes to solve pointing discrepancies\n",
    "    * unmapped down from ~350 to 249\n",
    "\n",
    "Good thing is, most of these lemmas appear to be relatively rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Field:\n",
    "For testing problems between the etcbc and bdb mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "תַּחַת\n",
      "אָוֶן\n",
      "רָאִיתִי\n",
      "אָהֳלֵי\n",
      "כוּשָׁן\n",
      "יִרְגְּזוּן\n",
      "יְרִיעוֹת\n",
      "אֶרֶץ\n",
      "מִדְיָן\n"
     ]
    }
   ],
   "source": [
    "test = T.nodeFromSection(('Habakkuk',3,7))\n",
    "test_words = [w for w in L.d(test, otype='word')]\n",
    "\n",
    "for w in test_words:\n",
    "    word = F.g_word_utf8.v(w)\n",
    "    print(fix_word(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The presence of a first position dagesh causes problems!\n",
    "# a new function could remove the dagesh and try again?\n",
    "\n",
    "bdb = 'כּוּשָׁן'\n",
    "etcbc = 'כוּשָׁן'\n",
    "\n",
    "bdb == etcbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdb[1] == 'ּ' # dagesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etcbc[1] == 'ּ' # dagesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'כוּשָׁן'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdb.replace('ּ','',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
